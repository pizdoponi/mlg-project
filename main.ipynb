{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We used a subset of WaterDrop dataset from Deepmind. The videos only covers the specific case of a water droplet in vacuum, but that is fine with us, as that is exactly what we wanted to model!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting TFRecord to torch tensors\n",
    "\n",
    "Unfortunately, the dataset is not available in a format that is easy to use with PyTorch. We need to convert it to a format that is more suitable for PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['simulation_trajectory_0', 'simulation_trajectory_1']\n",
      "<numpy.lib.npyio.NpzFile object at 0x000001F529CDC940>\n"
     ]
    }
   ],
   "source": [
    "# links:\n",
    "# https://github.com/geoelements/gns\n",
    "# https://dataverse-prod.tdl.org/dataset.xhtml?persistentId=doi:10.18738/T8/HUBMDM\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data = np.load('dataset/WaterDropSample/train.npz', mmap_mode='r', allow_pickle=True)\n",
    "\n",
    "print(data.files)\n",
    "'''print(data[\"simulation_trajectory_0\"][0].shape) -> (1000, 678, 2)\n",
    "print(data[\"simulation_trajectory_0\"][0][0].shape) -> (678, 2)\n",
    "print(data[\"simulation_trajectory_0\"][1].shape)  -> (678,)\n",
    "print(data[\"simulation_trajectory_1\"][0].shape)#  -> (100, 355, 2)\n",
    "print(data[\"simulation_trajectory_1\"][0][0].shape)#  -> (355, 2)\n",
    "print(data[\"simulation_trajectory_1\"][1].shape)#  -> (355,)'''\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "1. Apply noise to the training to mitigate error accumulation over long rollouts. We use a simple approach to make the model more robust to noisy inputs: at training we corrupt the input velocities of the model with random-walk noise N (0, $\\sigma_v$ = 0.0003) (adjusting input positions), so the training distribution is closer to the distribution generated during rollouts. \n",
    "2. Normalize all input and target vectors elementwise to zero mean and unit variance, using statistics computed online during training. Preliminary experiments showed that normalization led to faster training, though converged performance was not noticeably improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP\n",
    "\n",
    "MLP is used in a lot of different places throughout the architecture, most notably the encoder and the decoder are both MLPs. We define it as a class to make it easier to use.\n",
    "\n",
    "All MLPs have two hidden layers (with ReLU activations), followed by a nonactivated output layer, each layer with size of 128. All MLPs (except the output decoder) are followed by a LayerNorm layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=128, layer_norm=True):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.layer2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.layer3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.layer_norm = layer_norm\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        # The rationale behind setting the standard deviation of the normal distribution to 1/sqrt(layer.in_features)\n",
    "        # is to normalize the variance of the layer's inputs and outputs. This helps to prevent the outputs\n",
    "        # from exploding or vanishing during training. The 1/sqrt(layer.in_features) factor is based on the recommendation\n",
    "        # in the paper \"Understanding the difficulty of training deep feedforward neural networks\" by Glorot and Bengio (2010).\n",
    "        self.layer1.weight.data.normal_(0, 1 / torch.sqrt(self.layer1.in_features))\n",
    "        # Setting the bias to 0 allows the network to learn the appropriate bias values during training.\n",
    "        self.layer1.bias.data.fill_(0)\n",
    "        # The same reasoning applies to the other layers.\n",
    "        self.layer2.weight.data.normal_(0, 1 / torch.sqrt(self.layer2.in_features))\n",
    "        self.layer2.bias.data.fill_(0)\n",
    "        self.layer3.weight.data.normal_(0, 1 / torch.sqrt(self.layer3.in_features))\n",
    "        self.layer3.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.layer2(x)\n",
    "        if self.layer_norm:\n",
    "            x = nn.LayerNorm(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN Layer\n",
    "Here we implement InteractionNetwork\\\n",
    "paper: https://proceedings.neurips.cc/paper_files/paper/2016/file/3147da8ab4a0437c15ef51a5cc7f2dc4-Paper.pdf\n",
    "\n",
    "We use MPL that we defined above to generate messages for nodes and edges.\n",
    "\n",
    "Updaed features for nodes, `v_i` and edges, `e_ij`:\n",
    "\n",
    "$$\n",
    "v_i^{k+1} = v_i^k + MLP_n(v_i^k, \\sum_{v_j \\in N(v_i)}{MPL_e(v_i^k, v_j^k, e_ij^k)}) \\\\\n",
    "$$ \n",
    "$$ e_ij^{k+1} = e_ij^k + MLP_e(v_i^k, v_j^k, e_ij^k) $$\n",
    "\n",
    "where $MLP_e(\\cdot, \\cdot, \\cdot)$ is only computed once and then used twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_scatter import scatter\n",
    "from torch import cat\n",
    "\n",
    "class InteractionNetwork(MessagePassing):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.node_msg = MLP(2 * hidden_dim, hidden_dim, hidden_dim)\n",
    "        self.edge_msg = MLP(3 * hidden_dim, hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_feature):\n",
    "        # propagate invokes message() and aggregate(), which return (inputs, out)\n",
    "        # we update edge feature as: current edge feature + current message passing it\n",
    "        edge_out, aggr = self.propagate(edge_index, x=(x, x), edge_feature=edge_feature)\n",
    "        edge_out = edge_feature + edge_out\n",
    "\n",
    "        # we update node features as: sum of neigbouring messages and current\n",
    "        # node feature get passed through coresponding MLP.\n",
    "        # To include self correction a bit we add current feature to that output\n",
    "        node_out = x + self.node_msg(cat((x, aggr), dim=-1))\n",
    "\n",
    "        return node_out, edge_out\n",
    "\n",
    "    def message(self, x_i, x_j, edge_feature):\n",
    "        # here we create messages as an output of MPL with 3 inputs:\n",
    "        # edge feature and feature of each node connected by this edge\n",
    "        x = self.edge_msg(cat((x_i, x_j, edge_feature), dim=-1))\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def aggregate(self, source, index, dim_size=None):\n",
    "        # we sum all neighbouring messages for each node, which we will use to \n",
    "        # update next layer of node features\n",
    "        out = scatter(source, index, dim_size=dim_size, dim=self.node_dim, reduce=\"sum\")\n",
    "\n",
    "        return (source, out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Network-based Simulator (GNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Embedding, ModuleList\n",
    "\n",
    "class GNS(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim = 128,\n",
    "        num_types = 9,\n",
    "        emb_dim = 16,\n",
    "        num_gnn_layers = 5,\n",
    "        simulation_dim = 2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # IMPORTANT: this is the input dimension of data. It means that the model\n",
    "        # gets data from 2 previouos frames(2*sim_dim) plus the embedding.\n",
    "        # this variable is precomputed here for transparency and used in node_input\n",
    "        node_input_dim = 2 * simulation_dim + emb_dim\n",
    "        \n",
    "        # classic torch.nn Embedding\n",
    "        self.embedding = Embedding(num_types, emb_dim)\n",
    "\n",
    "        # node inputs and outputs\n",
    "        self.node_input = MLP(node_input_dim, hidden_dim, hidden_dim)\n",
    "        self.node_outpt = MLP(hidden_dim, hidden_dim, simulation_dim)\n",
    "\n",
    "        self.edge_input = MLP(simulation_dim + 1, hidden_dim, hidden_dim, layer_norm=False)\n",
    "\n",
    "        # initialize gnn layers as InteractionNetwork layers\n",
    "        self.gnns = ModuleList([InteractionNetwork(hidden_dim) for i in range(num_gnn_layers)])\n",
    "\n",
    "        # just save number of layers for later use\n",
    "        self.num_gnns = num_gnn_layers\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # first we embed the data into features\n",
    "        # SELF NOTE: I was guessing that `data` will have keys `x`, `pos`, `edge_attr` and `edge_index`\n",
    "        node_features = self.node_input(cat(self.embedding(data.x), data.pos), dim=-1)\n",
    "        edge_features = self.edge_input(data.edge_attr)\n",
    "\n",
    "        # then propagate them trough model layers\n",
    "        for gnn in self.gnns:\n",
    "            node_features, edge_features = gnn(x=node_features, edge_features=edge_features, edge_index=data.edge_index)\n",
    "\n",
    "        # and finally return node positions, in our case: x, y coordinates\n",
    "        node_output = self.node_outpt(node_features)\n",
    "\n",
    "        return node_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
