{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We used a subset of WaterDrop dataset from Deepmind. The videos only covers the specific case of a water droplet in vacuum, but that is fine with us, as that is exactly what we wanted to model!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting TFRecord to torch tensors\n",
    "\n",
    "Unfortunately, the dataset is not available in a format that is easy to use with PyTorch. We need to convert it to a format that is more suitable for PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 17:21:01.773827: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 17:21:13.251536: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': array([0]), 'particle_type': array([[5, 0, 0, ..., 0, 0, 5]], dtype=uint8)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# for example in tf.data.TFRecordDataset(\"./dataset/WaterDropSample/test.tfrecord\").take(1):\n",
    "#     parsed_example = tf.train.Example.FromString(example.numpy())\n",
    "#     print(parsed_example.features.feature)\n",
    "\n",
    "raw_dataset = tf.data.TFRecordDataset(\"./dataset/WaterDropSample/test.tfrecord\")\n",
    "\n",
    "for raw_record in raw_dataset.take(1):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    # print(example)\n",
    "    \n",
    "    result = {}\n",
    "    # example.features.feature is the dictionary\n",
    "    for key, feature in example.features.feature.items():\n",
    "    # The values are the Feature objects which contain a `kind` which contains:\n",
    "    # one of three fields: bytes_list, float_list, int64_list\n",
    "\n",
    "        kind = feature.WhichOneof('kind')\n",
    "        #print(kind)\n",
    "        result[key] = np.array(getattr(feature, kind).value)\n",
    "        #print(result[key])\n",
    "        #print(result[key].dtype.type)\n",
    "\n",
    "        # exmaple: particle_type: bytes_list -> numpy array unit8 (= byte array)\n",
    "        # looks like we don't need conversion of float_list and int64_list types (not proven)\n",
    "        if result[key].dtype.type == np.bytes_:\n",
    "            arr = np.frombuffer(b''.join(result[key]), dtype=np.uint8)\n",
    "            arr = arr.reshape((-1, len(result[key][0])))\n",
    "            result[key] = arr\n",
    "            #print(\"akka\")\n",
    "\n",
    "    print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "1. Apply noise to the training to mitigate error accumulation over long rollouts. We use a simple approach to make the model more robust to noisy inputs: at training we corrupt the input velocities of the model with random-walk noise N (0, $\\sigma_v$ = 0.0003) (adjusting input positions), so the training distribution is closer to the distribution generated during rollouts. \n",
    "2. Normalize all input and target vectors elementwise to zero mean and unit variance, using statistics computed online during training. Preliminary experiments showed that normalization led to faster training, though converged performance was not noticeably improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP\n",
    "\n",
    "MLP is used in a lot of different places throughout the architecture, most notably the encoder and the decoder are both MLPs. We define it as a class to make it easier to use.\n",
    "\n",
    "All MLPs have two hidden layers (with ReLU activations), followed by a nonactivated output layer, each layer with size of 128. All MLPs (except the output decoder) are followed by a LayerNorm layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=128, layer_norm=True):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.layer2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.layer3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.layer_norm = layer_norm\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        # The rationale behind setting the standard deviation of the normal distribution to 1/sqrt(layer.in_features)\n",
    "        # is to normalize the variance of the layer's inputs and outputs. This helps to prevent the outputs\n",
    "        # from exploding or vanishing during training. The 1/sqrt(layer.in_features) factor is based on the recommendation\n",
    "        # in the paper \"Understanding the difficulty of training deep feedforward neural networks\" by Glorot and Bengio (2010).\n",
    "        self.layer1.weight.data.normal_(0, 1 / torch.sqrt(self.layer1.in_features))\n",
    "        # Setting the bias to 0 allows the network to learn the appropriate bias values during training.\n",
    "        self.layer1.bias.data.fill_(0)\n",
    "        # The same reasoning applies to the other layers.\n",
    "        self.layer2.weight.data.normal_(0, 1 / torch.sqrt(self.layer2.in_features))\n",
    "        self.layer2.bias.data.fill_(0)\n",
    "        self.layer3.weight.data.normal_(0, 1 / torch.sqrt(self.layer3.in_features))\n",
    "        self.layer3.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.layer2(x)\n",
    "        if self.layer_norm:\n",
    "            x = nn.LayerNorm(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN Layer\n",
    "Here we implement InteractionNetwork\\\n",
    "paper: https://proceedings.neurips.cc/paper_files/paper/2016/file/3147da8ab4a0437c15ef51a5cc7f2dc4-Paper.pdf\n",
    "\n",
    "We use MPL that we defined above to generate messages for nodes and edges.\n",
    "\n",
    "Updaed features for nodes, `v_i` and edges, `e_ij`:\n",
    "\n",
    "$$\n",
    "v_i^{k+1} = v_i^k + MLP_n(v_i^k, \\sum_{v_j \\in N(v_i)}{MPL_e(v_i^k, v_j^k, e_ij^k)}) \\\\\n",
    "$$ \n",
    "$$ e_ij^{k+1} = e_ij^k + MLP_e(v_i^k, v_j^k, e_ij^k) $$\n",
    "\n",
    "where $MLP_e(\\cdot, \\cdot, \\cdot)$ is only computed once and then used twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_scatter import scatter\n",
    "from torch import cat\n",
    "\n",
    "class InteractionNetwork(MessagePassing):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.node_msg = MLP(2 * hidden_dim, hidden_dim, hidden_dim)\n",
    "        self.edge_msg = MLP(3 * hidden_dim, hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_feature):\n",
    "        # propagate invokes message() and aggregate(), which return (inputs, out)\n",
    "        # we update edge feature as: current edge feature + current message passing it\n",
    "        edge_out, aggr = self.propagate(edge_index, x=(x, x), edge_feature=edge_feature)\n",
    "        edge_out = edge_feature + edge_out\n",
    "\n",
    "        # we update node features as: sum of neigbouring messages and current\n",
    "        # node feature get passed through coresponding MLP.\n",
    "        # To include self correction a bit we add current feature to that output\n",
    "        node_out = x + self.node_msg(cat((x, aggr), dim=-1))\n",
    "\n",
    "        return node_out, edge_out\n",
    "\n",
    "    def message(self, x_i, x_j, edge_feature):\n",
    "        # here we create messages as an output of MPL with 3 inputs:\n",
    "        # edge feature and feature of each node connected by this edge\n",
    "        x = self.edge_msg(cat((x_i, x_j, edge_feature), dim=-1))\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def aggregate(self, source, index, dim_size=None):\n",
    "        # we sum all neighbouring messages for each node, which we will use to \n",
    "        # update next layer of node features\n",
    "        out = scatter(source, index, dim_size=dim_size, dim=self.node_dim, reduce=\"sum\")\n",
    "\n",
    "        return (source, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Embedding, ModuleList\n",
    "\n",
    "class GNS(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim = 128,\n",
    "        num_types = 9,\n",
    "        emb_dim = 16,\n",
    "        num_gnn_layers = 5,\n",
    "        simulation_dim = 2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # IMPORTANT: this is the input dimension of data. It means that the model\n",
    "        # gets data from 2 previouos frames(2*sim_dim) plus the embedding.\n",
    "        # this variable is precomputed here for transparency and used in node_input\n",
    "        node_input_dim = 2 * simulation_dim + emb_dim\n",
    "        \n",
    "        # classic torch.nn Embedding\n",
    "        self.embedding = Embedding(num_types, emb_dim)\n",
    "\n",
    "        # node inputs and outputs\n",
    "        self.node_input = MLP(node_input_dim, hidden_dim, hidden_dim)\n",
    "        self.node_outpt = MLP(hidden_dim, hidden_dim, simulation_dim)\n",
    "\n",
    "        self.edge_input = MLP(simulation_dim + 1, hidden_dim, hidden_dim, layer_norm=False)\n",
    "\n",
    "        # initialize gnn layers as InteractionNetwork layers\n",
    "        self.gnns = ModuleList([InteractionNetwork(hidden_dim) for i in range(num_gnn_layers)])\n",
    "\n",
    "        # just save number of layers for later use\n",
    "        self.num_gnns = num_gnn_layers\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # first we embed the data into features\n",
    "        # SELF NOTE: I was guessing that `data` will have keys `x`, `pos`, `edge_attr` and `edge_index`\n",
    "        node_features = self.node_input(cat(self.embedding(data.x), data.pos), dim=-1)\n",
    "        edge_features = self.edge_input(data.edge_attr)\n",
    "\n",
    "        # then propagate them trough model layers\n",
    "        for gnn in self.gnns:\n",
    "            node_features, edge_features = gnn(x=node_features, edge_features=edge_features, edge_index=data.edge_index)\n",
    "\n",
    "        # and finally return node positions, in our case: x, y coordinates\n",
    "        node_output = self.node_outpt(node_features)\n",
    "\n",
    "        return node_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "        'input_dim': 3,\n",
    "        'output_dim': 3,\n",
    "        'hidden_dim': 128,\n",
    "        'layer_norm': True,\n",
    "        'lr': 0.01,\n",
    "        'weight_decay': 5e-3,\n",
    "        'batch_size': 2,\n",
    "        'epochs': 1,\n",
    "        'dropout': 0.5,\n",
    "        'opt': 'adam',\n",
    "        'validate_interval': 1000,\n",
    "        'save_model': True,\n",
    "        'model_path': './model.pt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric as pyg\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_onestep(model: torch.nn.Module, data_loader: pyg.data.Dataset, device: torch.device): # type: ignore\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for batch_number, data in enumerate(data_loader):\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        loss = F.mse_loss(out, data.y)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / (batch_number + 1) # reportUnboundVariable: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(args: dict[str, Any], model: torch.nn.Module, train_loader, valid_loader):\n",
    "    \n",
    "    # Set the device to GPU if available, otherwise CPU\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    # init optimiser\n",
    "    if args['opt'] == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "    elif args['opt'] == 'sgd':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "    else:\n",
    "        raise ValueError('Unknown optimizer: {}'.format(args['opt']))\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
    "    \n",
    "    # loss function\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    # track the losses to be able to plot the learning curve\n",
    "    train_loss = []\n",
    "    validate_loss = []\n",
    "    \n",
    "    # track the total number of steps\n",
    "    steps = 0\n",
    "    \n",
    "    # main train loop\n",
    "    for epoch in range(args['epochs']):\n",
    "        model.train()\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
    "        \n",
    "        # keep track of the total loss and the number of batches\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for data in progress_bar:\n",
    "            # forward pass\n",
    "            optimizer.zero_grad()\n",
    "            data = data.cuda()\n",
    "            out = model(data)\n",
    "            loss = loss_fn(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            # update progress bar\n",
    "            total_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            progress_bar.set_postfix({\"loss\": loss.item(), \"avg_loss\": total_loss / batch_count})\n",
    "            steps += 1\n",
    "            train_loss.append((steps, loss.item()))\n",
    "\n",
    "            # evaluation\n",
    "            if steps % args[\"validate_interval\"] == 0:\n",
    "                model.eval()\n",
    "                loss = validate_onestep(model, valid_loader, device)\n",
    "                validate_loss.append((steps, validate_loss))\n",
    "                tqdm.write(f\"\\nEval: Loss: {validate_loss}\")\n",
    "                model.train()\n",
    "    \n",
    "    if args['save_model']:\n",
    "        torch.save(model.state_dict(), args['model_path'])\n",
    "    \n",
    "    return train_loss, validate_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the actual initialization of the data, model and training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the actual training takes place\n",
    "train_dataset = None # TODO: init train dataset\n",
    "valid_dataset = None # TODO: init valid dataset\n",
    "\n",
    "train_loader = pyg.data.DataLoader(train_dataset, batch_size=args['batch_size'], drop_last=True, shuffle=True, pin_memory=True, num_workers=4)\n",
    "valid_loader = pyg.data.DataLoader(valid_dataset, batch_size=args['batch_size'], drop_last=True, shuffle=False, pin_memory=True, num_workers=4)\n",
    "\n",
    "model = None # TODO: init model to GNS\n",
    "\n",
    "train_loss, validate_loss = train(args, model, train_loader, valid_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visualize the loss curve\n",
    "plt.figure()\n",
    "plt.plot(*zip(*train_loss), label=\"train\")\n",
    "plt.plot(*zip(*validate_loss), label=\"valid\")\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
